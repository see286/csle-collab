import numpy as np
import pickle
import json
import os

class SimplePOMDP:
    """ç®€åŒ–çš„POMDPç±»"""
    def __init__(self, transition_model, observation_model, reward_model):
        self.transition_model = transition_model
        self.observation_model = observation_model
        self.reward_model = reward_model
        
        self.n_states = transition_model.shape[0]
        self.n_actions = transition_model.shape[1]
        self.n_observations = observation_model.shape[1]
        
        # åˆå§‹ä¿¡å¿µçŠ¶æ€ï¼ˆå‡åŒ€åˆ†å¸ƒï¼‰
        self.belief = np.ones(self.n_states) / self.n_states
    
    def update_belief(self, action, observation):
        """æ›´æ–°ä¿¡å¿µçŠ¶æ€ï¼ˆè´å¶æ–¯æ›´æ–°ï¼‰"""
        new_belief = np.zeros(self.n_states)
        
        for s_next in range(self.n_states):
            # P(s' | o, a, b) âˆ P(o | s') * Î£_s P(s' | s, a) * b(s)
            prob_o_given_s = self.observation_model[s_next, observation]
            sum_term = 0
            
            for s in range(self.n_states):
                sum_term += self.transition_model[s, action, s_next] * self.belief[s]
            
            new_belief[s_next] = prob_o_given_s * sum_term
        
        # å½’ä¸€åŒ–
        if new_belief.sum() > 0:
            new_belief /= new_belief.sum()
        else:
            new_belief = np.ones(self.n_states) / self.n_states
        
        self.belief = new_belief
        return self.belief
    
    def get_action_probabilities(self, belief=None):
        """è·å–æ¯ä¸ªåŠ¨ä½œçš„æ¦‚ç‡ï¼ˆç®€å•å¯å‘å¼ï¼‰"""
        if belief is None:
            belief = self.belief
        
        # è®¡ç®—æ¯ä¸ªåŠ¨ä½œçš„æœŸæœ›å¥–åŠ±
        expected_rewards = np.zeros(self.n_actions)
        
        for a in range(self.n_actions):
            for s in range(self.n_states):
                expected_rewards[a] += belief[s] * self.reward_model[s, a]
        
        # ä½¿ç”¨softmaxè½¬æ¢ä¸ºæ¦‚ç‡
        exp_rewards = np.exp(expected_rewards - np.max(expected_rewards))
        action_probs = exp_rewards / exp_rewards.sum()
        
        return action_probs
    
    def reset_belief(self):
        """é‡ç½®ä¿¡å¿µçŠ¶æ€"""
        self.belief = np.ones(self.n_states) / self.n_states

def main():
    # åŠ è½½ä¼°è®¡çš„æ¨¡å‹
    model_file = "/home/li/csle/estimated_models.pkl"
    
    if not os.path.exists(model_file):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_file}")
        print("è¯·å…ˆè¿è¡Œ: python3 ~/csle/system_identification_demo.py")
        return
    
    try:
        with open(model_file, 'rb') as f:
            models = pickle.load(f)
        
        print("âœ… æˆåŠŸåŠ è½½ä¼°è®¡çš„æ¨¡å‹")
        
        # åˆ›å»ºPOMDPå®ä¾‹
        pomdp = SimplePOMDP(
            models['transition_model'],
            models['observation_model'],
            models['reward_model']
        )
        
        print(f"âœ… POMDPåˆ›å»ºæˆåŠŸ")
        print(f"   - çŠ¶æ€æ•°: {pomdp.n_states}")
        print(f"   - åŠ¨ä½œæ•°: {pomdp.n_actions}")
        print(f"   - è§‚æµ‹æ•°: {pomdp.n_observations}")
        
        # æµ‹è¯•ä¿¡å¿µæ›´æ–°
        print("\nğŸ§ª æµ‹è¯•ä¿¡å¿µæ›´æ–°:")
        print(f"åˆå§‹ä¿¡å¿µ: {pomdp.belief}")
        
        # æ¨¡æ‹Ÿä¸€ä¸ªæ­¥éª¤
        test_action = 0
        test_observation = 0
        new_belief = pomdp.update_belief(test_action, test_observation)
        print(f"æ‰§è¡ŒåŠ¨ä½œ {test_action}ï¼Œè§‚æµ‹åˆ° {test_observation}")
        print(f"æ›´æ–°åä¿¡å¿µ: {new_belief}")
        
        # è·å–åŠ¨ä½œæ¦‚ç‡
        action_probs = pomdp.get_action_probabilities()
        print(f"\nåŠ¨ä½œæ¦‚ç‡åˆ†å¸ƒ: {action_probs}")
        
        # ä¿å­˜POMDPå¯¹è±¡
        pomdp_file = "/home/li/csle/pomdp_object.pkl"
        with open(pomdp_file, 'wb') as f:
            pickle.dump(pomdp, f)
        
        print(f"\nâœ… POMDPå¯¹è±¡å·²ä¿å­˜åˆ°: {pomdp_file}")
        
        # ä¿å­˜ç»™Cä½¿ç”¨çš„æ–‡ä»¶
        output_for_C = {
            'policy': {
                'type': 'heuristic_policy',
                'description': 'åŸºäºä¿¡å¿µçš„å¯å‘å¼ç­–ç•¥'
            },
            'action_probabilities': action_probs.tolist(),
            'belief_state': new_belief.tolist(),
            'n_states': pomdp.n_states,
            'n_actions': pomdp.n_actions,
            'model_info': 'åŸºäºCSLEè½¨è¿¹æ•°æ®çš„POMDPæ¨¡å‹'
        }
        
        output_file = '/home/li/csle/output_for_C.json'
        with open(output_file, 'w') as f:
            json.dump(output_for_C, f, indent=2)
        
        print(f"âœ… å·²ç”Ÿæˆç»™è§’è‰²Cçš„è¾“å‡ºæ–‡ä»¶: {output_file}")
        
        # æ˜¾ç¤ºç»™Cçš„äº§å‡ºæ‘˜è¦
        print("\nğŸ“¦ Day 4 å®Œæˆäº§å‡º:")
        print(f"   1. POMDPæ¨¡å‹æ–‡ä»¶: {pomdp_file}")
        print(f"   2. JSONé…ç½®æ–‡ä»¶: {output_file}")
        print(f"   3. åŠ¨ä½œæ¦‚ç‡: {action_probs}")
        
        print("\nğŸ¯ Day 4 ä»»åŠ¡å®Œæˆï¼å‡†å¤‡è¿›å…¥Day 5: PPOè®­ç»ƒ")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")

if __name__ == "__main__":
    main()
